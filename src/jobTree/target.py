#!/usr/bin/env python

#Copyright (C) 2011 by Benedict Paten (benedictpaten@gmail.com)
#
#Permission is hereby granted, free of charge, to any person obtaining a copy
#of this software and associated documentation files (the "Software"), to deal
#in the Software without restriction, including without limitation the rights
#to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#copies of the Software, and to permit persons to whom the Software is
#furnished to do so, subject to the following conditions:
#
#The above copyright notice and this permission notice shall be included in
#all copies or substantial portions of the Software.
#
#THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
#THE SOFTWARE.
from collections import namedtuple
import os
import sys
import importlib
from optparse import OptionParser
import xml.etree.cElementTree as ET
from abc import ABCMeta, abstractmethod
import tempfile
import uuid
import time
from jobTree.resource import ModuleDescriptor

try:
    import cPickle 
except ImportError:
    import pickle as cPickle
    
import logging
logger = logging.getLogger( __name__ )

from jobTree.lib.bioio import (setLoggingFromOptions, 
                               getTotalCpuTimeAndMemoryUsage, getTotalCpuTime)
from jobTree.common import setupJobTree, addOptions
from jobTree.leader import mainLoop

class Target(object):
    """
    Represents a unit of work in jobTree. Targets are composed into graphs
    which make up a workflow. 
    
    This public functions of this class and its  nested classes are the API 
    to jobTree. 
    """
    def __init__(self, memory=sys.maxint, cpu=sys.maxint, disk=sys.maxint):
        """
        This method must be called by any overiding constructor.
        
        Memory is the maximum number of bytes of memory the target will 
        require to run. Cpu is the number of cores required. 
        """
        self.memory = memory
        self.cpu = cpu
        self.disk = disk
        #Private class variables
        
        #See Target.addChild
        self._children = []
        #See Target.addFollowOn
        self._followOns = []
        #See Target.addService
        self._services = []
        #A follow-on, service or child of a target A, is a "successor" of A, if B
        #is a successor of A, then A is a predecessor of B. 
        self._predecessors = set()
        #Variables used for serialisation
        self.userModule = ModuleDescriptor.forModule(self.__module__)
        #See Target.rv()
        self._rvs = {}
     
    def run(self, fileStore):
        """
        Do user stuff here, including creating any follow on jobs.
        
        The fileStore argument is an instance of Target.FileStore, and can
        be used to create temporary files which can be shared between targets.
        
        The return values of the function can be passed to other targets
        by means of the rv() function. 
        
        If the return value is a tuple, rv(i) would refer to the ith (indexed from 0)
        member of the tuple. If the return value is not a tuple then rV(0) or rV() would
        refer to the return value of the function. 
        
        Note: We disallow return values to be PromisedTargetReturnValue instances 
        (generated by the Target.rv() function - see below). 
        A check is made that will result in a runtime error if you attempt to do this.
        Allowing PromisedTargetReturnValue instances to be returned does not work because
        the mechanism to pass the promise uses a jobStoreFileID that will be deleted once
        the current job and its descendants have been completed. This is similar to
        scope rules in a language like C, where returning a reference to memory allocated
        on the stack within a function will produce an undefined reference. 
        Disallowing this also avoids nested promises (PromisedTargetReturnValue 
        instances that contain other PromisedTargetReturnValue). 
        """
        pass
    
    def addChild(self, childTarget):
        """
        Adds the child target to be run as child of this target. Returns childTarget.
        Child targets are run after the Target.run method has completed.
        
        See Target.checkTargetGraphAcylic for formal definition of allowed forms of
        target graph.
        """
        self._children.append(childTarget)
        childTarget._addPredecessor(self)
        return childTarget
    
    def addService(self, service):
        """
        Add a service of type Target.Service. The Target.Service.start() method 
        will be called after the run method has completed but before any successors 
        are run. It's Target.Service.stop() method will be called once the 
        successors of the target have been run.
        
        :rtype : An instance of PromisedTargetReturnValue which will be replaced
        with the return value from the service.start() in any successor of the job. 
        """
        targetService = ServiceTarget(service)
        self._services.append(targetService)
        return targetService.rv()
    
    def addFollowOn(self, followOnTarget):
        """
        Adds a follow-on target, follow-on targets will be run
        after the child targets and their descendants have been run. 
        Returns followOnTarget.
        
        See Target.checkTargetGraphAcylic for formal definition of allowed forms of
        target graph.
        """
        self._followOns.append(followOnTarget)
        followOnTarget._addPredecessor(self)
        return followOnTarget
    
    ##Convenience functions for creating targets
    
    def addChildFn(self, fn, *args, **kwargs):
        """
        Adds a child fn. See FunctionWrappingTarget. 
        Returns the new child Target.
        """
        return self.addChild(FunctionWrappingTarget(fn, *args, **kwargs))

    def addChildTargetFn(self, fn, *args, **kwargs):
        """
        Adds a child target fn. See TargetFunctionWrappingTarget. 
        Returns the new child Target.
        """
        return self.addChild(TargetFunctionWrappingTarget(fn, *args, **kwargs)) 
    
    def addFollowOnFn(self, fn, *args, **kwargs):
        """
        Adds a follow-on fn. See FunctionWrappingTarget. 
        Returns the new follow-on Target.
        """
        return self.addFollowOn(FunctionWrappingTarget(fn, *args, **kwargs))

    def addFollowOnTargetFn(self, fn, *args, **kwargs):
        """
        Add a follow-on target fn. See TargetFunctionWrappingTarget. 
        Returns the new follow-on Target.
        """
        return self.addFollowOn(TargetFunctionWrappingTarget(fn, *args, **kwargs)) 
    
    @staticmethod
    def wrapTargetFn(fn, *args, **kwargs):
        """
        Makes a Target out of a target function.
        
        Convenience function for constructor of TargetFunctionWrappingTarget
        """
        return TargetFunctionWrappingTarget(fn, *args, **kwargs)
 
    @staticmethod
    def wrapFn(fn, *args, **kwargs):
        """
        Makes a Target out of a function.
        
        Convenience function for constructor of FunctionWrappingTarget
        """
        return FunctionWrappingTarget(fn, *args, **kwargs)
    
    def encapsulate(self):
        """
        See EncapsulatedTarget.
        
        :rtype : A new EncapsulatedTarget for this target.
        """
        return EncapsulatedTarget(self)
    
    ####################################################
    #The following function is used for passing return values between 
    #target run functions
    ####################################################
    
    def rv(self, argIndex=0):
        """
        Gets a PromisedTargetReturnValue, representing the argIndex return 
        value of the run function (see run method for description).
        This PromisedTargetReturnValue, if a class attribute of a Target instance, 
        call it T, will be replaced by the actual return value just before the 
        run function of T is called. The function rv therefore allows the output 
        from one Target to be wired as input to another Target before either 
        is actually run.  
        """
        #Check if the return value has already been promised and if it has
        #return it
        if argIndex in self._rvs:
            return self._rvs[argIndex]
        #Create, store, return new PromisedTargetReturnValue
        self._rvs[argIndex] = PromisedTargetReturnValue()
        return self._rvs[argIndex]
    
    ####################################################
    #Cycle/connectivity checking
    ####################################################
    
    def checkTargetGraphForDeadlocks(self):
        """
        Raises a TargetGraphDeadlockException exception if the target graph
        is cyclic or contains multiple roots.
        """
        self.checkTargetGraphConnected()
        self.checkTargetGraphAcylic()
    
    def getRootTargets(self):
        """
        A root is a target with no predecessors. 
        :rtype : set, the roots of the connected component of targets that 
        contains this target.
        """
        roots = set()
        visited = set() 
        #Function to get the roots of a target
        def getRoots(target):
            if target not in visited:
                visited.add(target)
                if len(target._predecessors) > 0:
                    map(lambda p : getRoots(p), target._predecessors)
                else:
                    roots.add(target)
                #The following call ensures we explore all successor edges.
                map(lambda c : getRoots(c), target._children + 
                    target._followOns + target._services)
        getRoots(self)
        return roots
    
    def checkTargetGraphConnected(self):
        """
        Raises a TargetGraphDeadlockException exception if getRootTargets() does not 
        contain exactly one root target.
        As execution always starts from one root target, having multiple root targets will
        cause a deadlock to occur.
        """
        rootTargets = self.getRootTargets()
        if len(rootTargets) != 1:
            raise TargetGraphDeadlockException("Graph does not contain exactly one root targets: %s" % rootTargets)
    
    def checkTargetGraphAcylic(self):
        """
        Raises a TargetGraphDeadlockException exception if the connected component
        of targets containing this target contains any cycles of child/followOn dependencies 
        in the augmented target graph (see below). Such cycles are not allowed 
        in valid target graphs. This function is run during execution.
        
        A target B that is on a directed path of child/followOn edges from a 
        target A in the target graph is a descendant of A, 
        similarly A is an ancestor of B.
        
        A follow-on edge (A, B) between two targets A and B is equivalent 
        to adding a child edge to B from (1) A, (2) from each child of A, 
        and (3) from the descendants of each child of A. We
        call such an edge an "implied" edge. The augmented target graph is a 
        target graph including all the implied edges. 

        For a target (V, E) the algorithm is O(|V|^2). It is O(|V| + |E|) for 
        a graph with no follow-ons. The former follow on case could be improved!
        """
        #Get the root targets
        roots = self.getRootTargets()
        if len(roots) == 0:
            raise TargetGraphDeadlockException("Graph contains no root targets due to cycles")
        
        #Get implied edges
        extraEdges = self._getImpliedEdges(roots)
            
        #Check for directed cycles in the augmented graph
        visited = set()
        for root in roots:
            root._checkTargetGraphAcylicDFS([], visited, extraEdges)
    
    ####################################################
    #The following nested classes are used for
    #creating job trees (Target.Runner), 
    #managing temporary files (Target.FileStore),
    #and defining a service (Target.Service)
    ####################################################
    
    class Runner(object):
        """
        Used to setup and run a graph of targets.
        """
    
        @staticmethod
        def getDefaultOptions():
            """
            Returns an optparse.Values object of the 
            options used by a jobTree. 
            """
            parser = OptionParser()
            Target.Runner.addJobTreeOptions(parser)
            options, args = parser.parse_args(args=[])
            assert len(args) == 0
            return options
            
        @staticmethod
        def addJobTreeOptions(parser):
            """
            Adds the default jobTree options to an optparse or argparse
            parser object.
            """
            addOptions(parser)
    
        @staticmethod
        def startJobTree(target, options):
            """
            Runs the jobtree using the given options (see Target.Runner.getDefaultOptions
            and Target.Runner.addJobTreeOptions) starting with this target.
            
            Raises an exception if the given jobTree already exists. 
            """
            setLoggingFromOptions(options)
            with setupJobTree(options) as (config, batchSystem, jobStore):
                jobStore.clean()
                if "rootJob" not in config.attrib: #No jobs have yet been run
                    # Setup the first job.
                    rootJob = target._serialiseFirstTarget(jobStore)
                else:
                    rootJob = jobStore.load(config.attrib["rootJob"])
                return mainLoop(config, batchSystem, jobStore, rootJob)
        
        @staticmethod
        def cleanup(options):
            """
            Removes the jobStore backing the jobTree.
            """
            with setupJobTree(options) as (config, batchSystem, jobStore):
                jobStore.deleteJobStore()
            
    class FileStore:
        """
        Class used to manage temporary files and log messages, 
        passed as argument to the Target.run method.
        """
        
        def __init__(self, jobStore, job, localTempDir):
            """
            This constructor should not be called by the user, 
            FileStore instances are only provided as arguments 
            to the run function.
            """
            self.jobStore = jobStore
            self.job = job
            self.localTempDir = localTempDir
            self.loggingMessages = []
        
        def writeGlobalFile(self, localFileName):
            """
            Takes a file (as a path) and uploads it to to the global file store, returns
            an ID that can be used to retrieve the file. 
            """
            return self.jobStore.writeFile(self.job.jobStoreID, localFileName)
        
        def updateGlobalFile(self, fileStoreID, localFileName):
            """
            Replaces the existing version of a file in the global file store, 
            keyed by the fileStoreID. 
            Throws an exception if the file does not exist.
            """
            self.jobStore.updateFile(fileStoreID, localFileName)
        
        def readGlobalFile(self, fileStoreID, localFilePath=None):
            """
            Returns a path to a local copy of the file keyed by fileStoreID. 
            The version will be consistent with the last copy of the file 
            written/updated to the global file store. If localFilePath is not None, 
            the returned file path will be localFilePath.
            """
            if localFilePath is None:
                fd, localFilePath = tempfile.mkstemp(dir=self.getLocalTempDir())
                self.jobStore.readFile(fileStoreID, localFilePath)
                os.close(fd)
            else:
                self.jobStore.readFile(fileStoreID, localFilePath)
            return localFilePath
        
        def deleteGlobalFile(self, fileStoreID):
            """
            Deletes a global file with the given fileStoreID. Returns true if 
            file exists, else false.
            """
            return self.jobStore.deleteFile(fileStoreID)
        
        def writeGlobalFileStream(self):
            """
            Similar to writeGlobalFile, but returns a context manager yielding a 
            tuple of 1) a file handle which can be written to and 2) the ID of 
            the resulting file in the job store. The yielded file handle does 
            not need to and should not be closed explicitly.
            """
            return self.jobStore.writeFileStream(self.job.jobStoreID)
        
        def updateGlobalFileStream(self, fileStoreID):
            """
            Similar to updateGlobalFile, but returns a context manager yielding 
            a file handle which can be written to. The yielded file handle does 
            not need to and should not be closed explicitly.
            """
            return self.jobStore.updateFileStream(fileStoreID)
        
        def getEmptyFileStoreID(self):
            """
            Returns the ID of a new, empty file.
            """
            return self.jobStore.getEmptyFileStoreID(self.job.jobStoreID)
        
        def globalFileExists(self, fileStoreID):
            """
            :rtype : True if and only if the jobStore contains the given fileStoreID, else
            false.
            """
            return self.jobStore.fileExists(fileStoreID)
        
        def readGlobalFileStream(self, fileStoreID):
            """
            Similar to readGlobalFile, but returns a context manager yielding a 
            file handle which can be read from. The yielded file handle does not 
            need to and should not be closed explicitly.
            """
            return self.jobStore.readFileStream(fileStoreID)
           
        def getLocalTempDir(self):
            """
            Get the local temporary directory. This directory will exist for the 
            duration of the target only, and is guaranteed to be deleted once 
            the target terminates.
            """
            return self.localTempDir
        
        def logToMaster(self, string):
            """
            Send a logging message to the leader. Will only ne reported if logging 
            is set to INFO level (or lower) in the leader.
            """
            self.loggingMessages.append(str(string))
    
    class Service:
        """
        Abstract class used to define the interface to a service.
        """
        __metaclass__ = ABCMeta
        def __init__(self, memory=sys.maxint, cpu=sys.maxint):
            """
            Memory and cpu requirements are specified identically to the Target
            constructor.
            """
            self.memory = memory
            self.cpu = cpu
        
        @abstractmethod       
        def start(self):
            """
            Start the service.
            
            :rtype : An object describing how to access the service. Must be 
            pickleable. Will be used by a target to access the service.
            """
            pass
        
        @abstractmethod
        def stop(self):
            """
            Stops the service.
            
            Function can block until complete. 
            """
            pass

    ####################################################
    #Private functions
    ####################################################
    
    def _addPredecessor(self, predecessorTarget):
        """
        Adds a predecessor target to the set of predecessor targets. Raises a 
        RuntimeError is the target is already a predecessor.
        """
        if predecessorTarget in self._predecessors:
            raise RuntimeError("The given target is already a predecessor of this target")
        self._predecessors.add(predecessorTarget)

    ####################################################
    #The following functions are used to serialise
    #a target graph to the jobStore
    ####################################################
    
    def _getHashOfTargetsToUUIDs(self, targetsToUUIDs):
        """
        Creates a map of the targets in the graph to randomly selected UUIDs.
        Excludes the root target.
        """
        #Call recursively
        for successor in self._children + self._followOns:
            successor._getHashOfTargetsToUUIDs2(targetsToUUIDs)
        return targetsToUUIDs
        
    def getUserScript(self):
        return self.userModule

    def _getHashOfTargetsToUUIDs2(self, targetsToUUIDs):
        if self not in targetsToUUIDs:
            targetsToUUIDs[self] = str(uuid.uuid1())
            self._getHashOfTargetsToUUIDs(targetsToUUIDs)
           
    def _createEmptyJobForTarget(self, jobStore, updateID=None, command=None, 
                                 predecessorNumber=0):
        """
        Create an empty job for the target.
        """
        return jobStore.create(command=command, 
                               memory=(self.memory if self.memory != sys.maxint 
                                       else float(jobStore.config.attrib["default_memory"])),
                               cpu=(self.cpu if self.cpu != sys.maxint
                                    else float(jobStore.config.attrib["default_cpu"])),
                               disk=(self.disk if self.disk != sys.maxint
                                    else float(jobStore.config.attrib["default_disk"])),
                               updateID=updateID, predecessorNumber=predecessorNumber)
        
    def _makeJobWrappers(self, jobStore, targetsToUUIDs, targetsToJobs, predecessor, rootJob):
        """
        Creates a job for each target in the target graph, recursively.
        """
        if self not in targetsToJobs:
            #The job for the target
            assert predecessor in self._predecessors
            job = self._createEmptyJobForTarget(jobStore, targetsToUUIDs[self],
                                                predecessorNumber=len(self._predecessors))
            targetsToJobs[self] = job
            
            #Add followOns/children to be run after the current target.
            for successors in (self._followOns, self._children):
                jobs = map(lambda successor:
                    successor._makeJobWrappers(jobStore, targetsToUUIDs, 
                                               targetsToJobs, self, rootJob), successors)
                if len(jobs) > 0:
                    job.stack.append(jobs)
            
            #Pickle the target so that its run method can be run at a later time.
            #Drop out the children/followOns/predecessors/services - which are 
            #all recored within the jobStore and do not need to be stored within 
            #the target
            self._children = []
            self._followOns = []
            self._services = []
            self._predecessors = set()
            #The pickled target is "run" as the command of the job, see worker
            #for the mechanism which unpickles the target and executes the Target.run
            #method.
            fileStoreID = jobStore.getEmptyFileStoreID(rootJob.jobStoreID)
            with jobStore.writeFileStream(rootJob.jobStoreID) as (fileHandle, fileStoreID):
                cPickle.dump(self, fileHandle, cPickle.HIGHEST_PROTOCOL)
            targetClassName = self.__class__.__name__
            job.command = ' '.join( ('scriptTree', fileStoreID, targetClassName) + self.userModule)
            #Update the status of the job on disk
            jobStore.update(job)
        else:
            #Lookup the already created job
            job = targetsToJobs[self]
            assert job.predecessorNumber > 1
        
        #The return is a tuple stored within the job.stack of the jobs to run.
        #The tuple is jobStoreID, memory, cpu, disk, predecessorID
        #The predecessorID is used to establish which predecessors have been
        #completed before running the given Target - it is just a unique ID
        #per predecessor 
        return (job.jobStoreID, job.memory, job.cpu, job.disk,
                None if job.predecessorNumber <= 1 else str(uuid.uuid4()))
    
    def _serialiseTargetGraph(self, job, jobStore):
        """
        Serialises the graph of targets rooted at this target, 
        storing them in the jobStore.
        Assumes the root target is already in the jobStore.
        """
        #Create jobIDs as UUIDs
        targetsToUUIDs = self._getHashOfTargetsToUUIDs({})
        #Set the jobs to delete
        job.jobsToDelete = list(targetsToUUIDs.values())
        #Update the job on disk. The jobs to delete is a record of what to
        #remove if the update goes wrong
        jobStore.update(job)
        #Create the jobs for followOns/children
        targetsToJobs = {}
        for successors in (self._followOns, self._children):
            jobs = map(lambda successor:
                successor._makeJobWrappers(jobStore, targetsToUUIDs, 
                                           targetsToJobs, self, job), successors)
            if len(jobs) > 0:
                job.stack.append(jobs)
        #Remove the jobs to delete list and remove the old command finishing the update
        job.jobsToDelete = []
        job.command = None
        jobStore.update(job)
        
    def _serialiseFirstTarget(self, jobStore):
        """
        Serialises the root target. Returns the wrapping job.
        """
        #Pickles the target within a shared file in the jobStore called 
        #"firstTarget"
        sharedTargetFile = "firstTarget"
        with jobStore.writeSharedFileStream(sharedTargetFile) as f:
            cPickle.dump(self, f, cPickle.HIGHEST_PROTOCOL)
        #Make the first job
        targetClassName = self.__class__.__name__
        command = ('scriptTree', sharedTargetFile, targetClassName) + self.userModule
        job = self._createEmptyJobForTarget(jobStore, command=' '.join( command ))
        #Set the config rootJob attrib
        assert "rootJob" not in jobStore.config.attrib
        jobStore.config.attrib["rootJob"] = job.jobStoreID
        with jobStore.writeSharedFileStream("config.xml") as f:
            ET.ElementTree( jobStore.config ).write(f)
        #Return the first job
        return job

    ####################################################
    #Functions to pass Target.run return values to the 
    #input arguments of other Target instances
    ####################################################
   
    def _switchOutPromisedTargetReturnValues(self, jobStore):
        """
        Replaces each PromisedTargetReturnValue instance that is a class 
        attribute of the target with PromisedTargetReturnValue's stored value.
        Will do this also for PromisedTargetReturnValue instances within lists, 
        tuples, sets or dictionaries that are class attributes of the Target.
        
        This function is called just before the run method.
        """

        # FIXME: why is the substitution only done one level deep? IOW, what about, say, a dict of lists

        # FIXME: This replaces subclasses of list, tuple and dict with the instances of the respective base ...
        # FIXME: ... class. For a potential fix, see my quick fix for tuples.

        # FIXME: This unnecessarily touches attributes that don't have a promise. It touches attributes of the ...
        # FIXME: ... target base classes which provably have no PromisedTargetReturnValues in them

        #Iterate on the class attributes of the Target instance.
        for attr, value in self.__dict__.iteritems():
            #If the variable is a PromisedTargetReturnValue replace with the 
            #actual stored return value of the PromisedTargetReturnValue
            #else if the variable is a list, tuple or set or dict replace any 
            #PromisedTargetReturnValue instances within
            #the container with the stored return value.

            # FIXME: This lambda might become more readable if "value" wasn't closed over but passed in.

            # FIXME: I find lambdas awkward. A simple nested def should suffice

            f = lambda : map(lambda x : x.loadValue(jobStore) if 
                        isinstance(x, PromisedTargetReturnValue) else x, value)
            if isinstance(value, PromisedTargetReturnValue):
                self.__dict__[attr] = value.loadValue(jobStore)
            elif isinstance(value, list):
                self.__dict__[attr] = f()
            elif value.__class__ == tuple:
                self.__dict__[attr] = tuple(f())
            elif isinstance(value, tuple):
                self.__dict__[attr] = value.__class__(*f())
            elif isinstance(value, set):
                self.__dict__[attr] = set(f())
            elif isinstance(value, dict):
                self.__dict__[attr] = dict(map(lambda x : (x, value[x].loadValue(jobStore) if 
                        isinstance(x, PromisedTargetReturnValue) else value[x]), value))
      
    def _setFileIDsForPromisedValues(self, jobStore, jobStoreID, visited):
        """
        Sets the jobStoreFileID for each PromisedTargetReturnValue in the 
        graph of targets created.
        """
        #Replace any None references with valid jobStoreFileIDs. We 
        #do this here, rather than within the original constructor of the
        #promised value because we don't necessarily have access to the jobStore when 
        #the PromisedTargetReturnValue instances are created.
        if self not in visited:
            visited.add(self)
            for PromisedTargetReturnValue in self._rvs.values():
                if PromisedTargetReturnValue.jobStoreFileID == None:
                    PromisedTargetReturnValue.jobStoreFileID = jobStore.getEmptyFileStoreID(jobStoreID)
            #Now recursively do the same for the children and follow ons.
            for successorTarget in self._children + self._followOns + self._services:
                successorTarget._setFileIDsForPromisedValues(jobStore, jobStoreID, visited)
    
    @staticmethod
    def _setReturnValuesForPromises(target, returnValues, jobStore):
        """
        Sets the values for promises using the return values from the target's
        run function.
        """
        for i in target._rvs.keys():
            if isinstance(returnValues, tuple):
                argToStore = returnValues[i]
            else:
                if i != 0:
                    raise RuntimeError("Referencing return value index (%s)"
                                " that is out of range: %s" % (i, returnValues))
                argToStore = returnValues
            target._rvs[i]._storeValue(argToStore, jobStore)
    
    ####################################################
    #Functions associated with Target.checkTargetGraphAcyclic to establish 
    #that the target graph does not contain any cycles of dependencies. 
    ####################################################
        
    def _dfs(self, visited):
        """Adds the target and all targets reachable on a directed path from current 
        node to the set 'visited'.
        """
        if self not in visited:
            visited.add(self) 
            for successor in self._children + self._followOns:
                successor._dfs(visited)
        
    def _checkTargetGraphAcylicDFS(self, stack, visited, extraEdges):
        """
        DFS traversal to detect cycles in augmented target graph.
        """
        if self not in visited:
            visited.add(self) 
            stack.append(self)
            for successor in self._children + self._followOns + extraEdges[self]:
                successor._checkTargetGraphAcylicDFS(stack, visited, extraEdges)
            assert stack.pop() == self
        if self in stack:
            stack.append(self)
            raise TargetGraphDeadlockException("A cycle of target dependencies has been detected '%s'" % stack)
    
    @staticmethod
    def _getImpliedEdges(roots):
        """
        Gets the set of implied edges. See Target.checkTargetGraphAcylic
        """
        #Get nodes in target graph
        nodes = set()
        for root in roots:
            root._dfs(nodes)
        
        ##For each follow-on edge calculate the extra implied edges
        #Adjacency list of implied edges, i.e. map of targets to lists of targets 
        #connected by an implied edge 
        extraEdges = dict(map(lambda n : (n, []), nodes))
        for target in nodes:
            if len(target._followOns) > 0:
                #Get set of targets connected by a directed path to target, starting
                #with a child edge
                reacheable = set()
                for child in target._children:
                    child._dfs(reacheable)
                #Now add extra edges
                for descendant in reacheable:
                    extraEdges[descendant] += target._followOns[:]
        return extraEdges 
    
    def _modifyTargetGraphForServices(self, fileStore):
        """
        Modifies the target graph to correctly schedule any services
        defined for this target.
        """
        if len(self._services) > 0:
            #Set the start/stop jobStore fileIDs for each service
            for service in self._services:
                service.startFileStoreID = fileStore.getEmptyFileStoreID()
                assert fileStore.globalFileExists(service.startFileStoreID)
                service.stopFileStoreID = fileStore.getEmptyFileStoreID()
                assert fileStore.globalFileExists(service.stopFileStoreID)
            
            def removePredecessor(target):
                assert self in target._predecessors
                target._predecessors.remove(self)
            
            #t1 and t2 are used to run the children and followOns of the target
            #after the services of the target are started
            startFileStoreIDs = map(lambda i : i.startFileStoreID, self._services)
            t1, t2 = Target.wrapTargetFn(blockUntilDeleted, startFileStoreIDs), Target()
            #t1 runs the children of the target
            for child in self._children:
                removePredecessor(child)
                t1.addChild(child)
            self._children = []
            #t2 runs the followOns of the target
            for followOn in self._followOns:
                removePredecessor(followOn)
                t2.addChild(followOn)
            self._followOns = []
            #Wire up the self, t1 and t2
            self.addChild(t1)
            t1.addFollowOn(t2)
            #Now make the services children of the target
            for service in self._services:
                self.addChild(service)
                assert service._predecessors == set((self,))
            #The final task once t1 and t2 have finished is to stop the services
            #this is achieved by deleting the stopFileStoreIDs.
            t2.addFollowOnTargetFn(deleteFileStoreIDs, map(lambda i : i.stopFileStoreID, self._services))
            self._services = [] #Defensive
    
    ####################################################
    #Function which worker calls to ultimately invoke
    #a targets Target.run method, and then handle created
    #children/followOn targets
    ####################################################
       
    def _execute(self, job, stats, localTempDir, jobStore):
        """This is the core method for running the target within a worker.
        """ 
        if stats != None:
            startTime = time.time()
            startClock = getTotalCpuTime()
        
        baseDir = os.getcwd()
        #Switch out any promised return value instances with the actual values
        self._switchOutPromisedTargetReturnValues(jobStore)
        #Run the target, first cleanup then run.
        fileStore = Target.FileStore(jobStore, job, localTempDir)
        returnValues = self.run(fileStore)
        #Check if the target graph has created
        #any cycles of dependencies or has multiple roots
        self.checkTargetGraphForDeadlocks()
        #Set the promised value jobStoreFileIDs
        self._setFileIDsForPromisedValues(jobStore, job.jobStoreID, set())
        #Store the return values for any promised return value
        self._setReturnValuesForPromises(self, returnValues, jobStore)
        #Modify target graph to run any services correctly
        self._modifyTargetGraphForServices(fileStore)
        #Turn the graph into a graph of jobs in the jobStore
        self._serialiseTargetGraph(job, jobStore)
        #Change dir back to cwd dir, if changed by target (this is a safety issue)
        if os.getcwd() != baseDir:
            os.chdir(baseDir)
        #Finish up the stats
        if stats != None:
            stats = ET.SubElement(stats, "target")
            stats.attrib["time"] = str(time.time() - startTime)
            totalCpuTime, totalMemoryUsage = getTotalCpuTimeAndMemoryUsage()
            stats.attrib["clock"] = str(totalCpuTime - startClock)
            stats.attrib["class"] = ".".join((self.__class__.__name__,))
            stats.attrib["memory"] = str(totalMemoryUsage)
        #Return any logToMaster logging messages
        return fileStore.loggingMessages
    
    ####################################################
    #Method used to resolve the module in which an inherited target instances
    #class is defined
    ####################################################
    
    @staticmethod
    def _resolveMainModule( moduleName ):
        """
        Returns a tuple of two elements, the first element being the path 
        to the directory containing the given
        module and the second element being the name of the module. 
        If the given module name is "__main__",
        then that is translated to the actual file name of the top-level 
        script without .py or .pyc extensions. The
        caller can then add the first element of the returned tuple to 
        sys.path and load the module from there. See also worker.loadTarget().
        """
        # looks up corresponding module in sys.modules, gets base name, drops .py or .pyc
        moduleDirPath, moduleName = os.path.split(os.path.abspath(sys.modules[moduleName].__file__))
        if moduleName.endswith('.py'):
            moduleName = moduleName[:-3]
        elif moduleName.endswith('.pyc'):
            moduleName = moduleName[:-4]
        else:
            raise RuntimeError(
                "Can only handle main modules loaded from .py or .pyc files, but not '%s'" %
                moduleName)
        return moduleDirPath, moduleName

class TargetGraphDeadlockException( Exception ):
    def __init__( self, string ):
        super( TargetGraphDeadlockException, self ).__init__( string )

class FunctionWrappingTarget(Target):
    """
    Target used to wrap a function.
    
    Function can not be nested function or class function, currently.
    *args and **kwargs are used as the arguments to the function.
    """
    def __init__(self, userFunction, *args, **kwargs):
        # FIXME: I'd rather not duplicate the defaults here, unless absolutely necessary
        cpu = kwargs.pop("cpu") if "cpu" in kwargs else sys.maxint
        disk = kwargs.pop("disk") if "disk" in kwargs else sys.maxint
        memory = kwargs.pop("memory") if "memory" in kwargs else sys.maxint
        Target.__init__(self, memory=memory, cpu=cpu, disk=disk)
        self.userFunctionModule = ModuleDescriptor.forModule(userFunction.__module__)
        self.userFunctionName = str(userFunction.__name__)
        self._args=args
        self._kwargs=kwargs
        
    def _getUserFunction(self):
        userFunctionModule = self.userFunctionModule.localize()
        if userFunctionModule.dirPath not in sys.path:
            # FIXME: prepending to sys.path will probably fix #103
            sys.path.append(userFunctionModule.dirPath)
        return getattr(importlib.import_module(userFunctionModule.name), self.userFunctionName)

    def run(self,fileStore):
        userFunction = self._getUserFunction( )
        return userFunction(*self._args, **self._kwargs)

    def getUserScript(self):
        return self.userFunctionModule

class TargetFunctionWrappingTarget(FunctionWrappingTarget):
    """
    Target used to wrap a function.
    A target function is a function which takes as its first argument a reference
    to the wrapping target. 
    
    To enable the target function to get access to the Target.FileStore
    instance (see Target.Run), it is made a variable of the wrapping target, so in the wrapped
    target function the attribute "fileStore" of the first argument (the target) is
    an instance of the Target.FileStore class. 
    """

    def __init__(self, userFunction, *args, **kwargs):
        super(TargetFunctionWrappingTarget, self).__init__(userFunction, *args, **kwargs)
        self.fileStore = None

    def run(self, fileStore):
        userFunction = self._getUserFunction()
        self.fileStore = fileStore
        return userFunction(*((self,) + tuple(self._args)), **self._kwargs)
    
class ServiceTarget(Target):
    """
    Target used to wrap a Target.Service instance. This constructor should
    not be called by a user.
    """
    def __init__(self, service):
        Target.__init__(self, memory=service.memory, cpu=service.cpu)
        self.service = service
        #An empty file in the jobStore which when deleted is used to signal
        #that the service should cease, is initialised in 
        #Target._modifyTargetGraphForServices
        self.stopFileStoreID = None
        #Similarly a empty file which when deleted is used to signal that the 
        #service is established
        self.startFileStoreID = None
        
    def run(self, fileStore):
        #Start the service
        startCredentials = self.service.start()
        #The start credentials  must be communicated to processes connecting to
        #the service, to do this while the run method is running we 
        #cheat and set the return value promise within the run method
        self._setReturnValuesForPromises(self, startCredentials, 
                                         fileStore.jobStore)
        self._rvs = {} #Set this to avoid the return values being updated after the 
        #run method has completed!
        #Now flag that the service is running jobs can connect to it
        assert self.startFileStoreID != None
        assert fileStore.globalFileExists(self.startFileStoreID)
        fileStore.deleteGlobalFile(self.startFileStoreID)
        assert not fileStore.globalFileExists(self.startFileStoreID)
        #Now block until we are told to stop, which is indicated by the removal 
        #of a file
        assert self.stopFileStoreID != None
        while fileStore.globalFileExists(self.stopFileStoreID):
            time.sleep(1) #Avoid excessive polling
        #Now kill the service
        self.service.stop()
        
class EncapsulatedTarget(Target):
    """
    An convenience Target class used to make a target subgraph appear to 
    be a single target. 
    
    Let A be a root target potentially with children and follow-ons.
    Without an encapsulated target the simplest way to specify a target B which 
    runs after A and all its successors is to create a parent of A' and then make B 
    a follow-on of A'. In turn if we wish to run C after B and its successors then we 
    repeat the process to create B', a parent of B, creating a graph in which A' is run,
    then A as a child of A', then the successors of A, then B' as a follow on of A', 
    then B as a child of B', then the successors of B, then finally C as follow on of B', 
    e.g.
    
    A, B, C = A(), B(), C() #Functions to create target graphs
    A' = Target()
    B' = Target()
    A'.addChild(A)
    A'.addFollowOn(B')
    B'.addChild(B)
    B'.addFollowOn(C)
    
    An encapsulated target of E(A) of A saves making A' and B', instead we can write:
    
    A, B, C = A().encapsulate(), B(), C() #Functions to create target graphs
    A.addChild(B)
    A.addFollowOn(C)
    
    Note the call to encapsulate creates the EncapsulatedTarget.
    """
    def __init__(self, target):
        """
        target is the target to encapsulate.
        """
        Target.__init__(self)
        Target.addChild(self, target)
        self.followOn = Target()
        Target.addFollowOn(self, self.followOn)
        
    def addChild(self, childTarget):
        return Target.addChild(self.followOn, childTarget)
    
    def addService(self, service):
        return Target.addService(self.followOn, service)
    
    def addFollowOn(self, followOnTarget):
        return Target.addFollowOn(self.followOn, followOnTarget)
    
    def rv(self, argIndex=0):
        return self.followOn.rv(argIndex)

class PromisedTargetReturnValue():
    """
    References a return value from a Target's run function. Let T be a target. 
    Instances of PromisedTargetReturnValue are created by
    T.rv(i), where i is an integer reference to a return value of T's run function
    (casting the return value as a tuple). 
    When passed to the constructor of a different Target the PromisedTargetReturnValue
    will be replaced by the actual referenced return value after the Target's run function 
    has finished (see Target._switchOutPromisedTargetReturnValues). 
    This mechanism allows a return values from one Target's run method to be input
    argument to Target before the former Target's run function has been executed.
    """ 
    def __init__(self):
        self.jobStoreFileID = None #The None value is
        #replaced with a real jobStoreFileID by the Target object.
        
    def loadValue(self, jobStore):
        """
        Unpickles the promised value and returns it. 
        """
        assert self.jobStoreFileID != None 
        with jobStore.readFileStream(self.jobStoreFileID) as fileHandle:
            value = cPickle.load(fileHandle) #If this doesn't work then the file containing the promise may not exist or be corrupted.
            if isinstance(value, PromisedTargetReturnValue):
                raise RuntimeError("A nested PromisedTargetReturnValue has been found.") #We do not allow the return of PromisedTargetReturnValue instance from the run function
            return value

    def _storeValue(self, valueToStore, jobStore):
        """
        Pickle the promised value. This is done by the target.
        """
        assert self.jobStoreFileID != None
        with jobStore.updateFileStream(self.jobStoreFileID) as fileHandle:
            cPickle.dump(valueToStore, fileHandle, cPickle.HIGHEST_PROTOCOL)

def deleteFileStoreIDs(target, jobStoreFileIDsToDelete):
    """
    Target function that deletes a bunch of files using their jobStoreFileIDs
    """
    map(lambda i : target.fileStore.deleteGlobalFile(i), jobStoreFileIDsToDelete)

def blockUntilDeleted(target, jobStoreFileIDs): 
    """
    Function will not terminate until all the fileStoreIDs in jobStoreFileIDs
    cease to exist.
    """
    while True:
        jobStoreFileIDs = [ i for i in jobStoreFileIDs 
                           if target.fileStore.globalFileExists(i) ]
        if len(jobStoreFileIDs) == 0:
            break
        time.sleep(1)
        
